{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "from numba import cuda\n",
    "import librosa.display\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile as wav\n",
    "from numpy.lib import stride_tricks\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('./spectrograms/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('./spectrograms/1c9a423f.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2arr = np.array(image) # im2arr.shape: height x width x channel\n",
    "# arr2im = Image.fromarray(im2arr)\n",
    "# arr2im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = tf.compat.v1.ConfigProto()\n",
    "configuration.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "tf.config.experimental.set_memory_growth(gpus[0],True)\n",
    "session = tf.compat.v1.Session(config=configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('instruments.csv')\n",
    "# df.set_index('fname', inplace=True)\n",
    "\n",
    "# for f in df.index:\n",
    "#     signal, rate = librosa.load('./cleaned/'+f)\n",
    "#     df.at[f, 'length'] = signal.shape[0]/rate\n",
    "\n",
    "# classes = list(np.unique(df.label))\n",
    "# class_dist = df.groupby(['label'])['length'].mean()\n",
    "\n",
    "# n_samples = 2 * int(df['length'].sum()/0.1)\n",
    "# prob_dist = class_dist /class_dist.sum()\n",
    "# choices = np.random.choice(class_dist.index, p=prob_dist)\n",
    "\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.set_title('Class Distribution', y=1.08)\n",
    "# ax.pie(class_dist, labels=class_dist.index, autopct='%1.1f%%',\n",
    "#        shadow=False, startangle=90)\n",
    "# ax.axis('equal')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classname =df[df.fname == \"5388d14d.wav\"].label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classname[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio(conf, pathname, trim_long_data):\n",
    "    y, sr = librosa.load(pathname, sr=conf.sampling_rate)\n",
    "    # trim silence\n",
    "    if 0 < len(y): # workaround: 0 length causes error\n",
    "        y, _ = librosa.effects.trim(y) # trim, top_db=default(60)\n",
    "    # make it unified length to conf.samples\n",
    "    if len(y) > conf.samples: # long enough\n",
    "        if trim_long_data:\n",
    "            y = y[0:0+conf.samples]\n",
    "    else: # pad blank\n",
    "        padding = conf.samples - len(y)    # add padding at both ends\n",
    "        offset = padding // 2\n",
    "        y = np.pad(y, (offset, conf.samples - len(y) - offset), 'constant')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_melspectrogram(conf, audio):\n",
    "    spectrogram = librosa.feature.melspectrogram(audio, \n",
    "                                                 sr=conf.sampling_rate,\n",
    "                                                 n_mels=conf.n_mels,\n",
    "                                                 hop_length=conf.hop_length,\n",
    "                                                 n_fft=conf.n_fft,\n",
    "                                                 fmin=conf.fmin,\n",
    "                                                 fmax=conf.fmax)\n",
    "    spectrogram = librosa.power_to_db(spectrogram)\n",
    "    spectrogram = spectrogram.astype(np.float32)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_as_melspectrogram(conf, pathname, trim_long_data, debug_display=False):\n",
    "    x = read_audio(conf, pathname, trim_long_data)\n",
    "    mels = audio_to_melspectrogram(conf, x)\n",
    "    return mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conf:\n",
    "    sampling_rate = 44100\n",
    "    duration = 2\n",
    "    hop_length = 347*duration # to make time steps 128\n",
    "    fmin = 20\n",
    "    fmax = sampling_rate // 2\n",
    "    n_mels = 128\n",
    "    n_fft = n_mels * 20\n",
    "    samples = sampling_rate * duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_from_sound(img_path):\n",
    "    filename = rename_file(img_path)\n",
    "    x = read_as_melspectrogram(conf, img_path, trim_long_data=True, debug_display=True)\n",
    "    \n",
    "    plt.imshow(x, interpolation='nearest')\n",
    "    #plt.savefig('./spectrograms/' + filename)\n",
    "    \n",
    "#     plt.close()\n",
    "#     del x\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image_from_sound('./spectrograms/1c9a423f.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_file(img_name):\n",
    "    img_name = img_name.split(\"/\")[2]\n",
    "    img_name = img_name[:-4]\n",
    "    img_name += \".jpg\"\n",
    "    return img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, fn in enumerate(os.listdir('./cleaned/')):\n",
    "    print(i)\n",
    "    path = './cleaned/' + fn\n",
    "    save_image_from_sound(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir('./spectrograms/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = images[0].split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavFile = temp[0] + '.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feats():\n",
    "    X = []\n",
    "    Y = []\n",
    "    for image in tqdm(os.listdir('./spectrograms/')):\n",
    "        print(image)\n",
    "        X.append(mpimg.imread('./spectrograms/' + image))\n",
    "        temp = image.split('.')\n",
    "        wavFile = temp[0] + '.wav'\n",
    "        \n",
    "        classname =df[df.fname == wavFile].label.values\n",
    "        Y.append(classname[0])\n",
    "    \n",
    "    X = np.asarray(X)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = build_feats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "Y = label_encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.keras.utils.to_categorical(Y,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64,kernel_size=3, activation = 'relu', input_shape=(288,432,3)))\n",
    "    model.add(Conv2D(32,kernel_size=3, activation = 'relu'))\n",
    "#     model.add(Conv2D(64,(3,3), activation = 'relu', strides=(1,1),\n",
    "#                     padding ='same'))\n",
    "#     model.add(Conv2D(128,(3,3), activation = 'relu', strides=(1,1),\n",
    "#                     padding ='same'))\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "#     model.add(Dense(64, activation ='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    print(type(model))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = get_conv_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnnScores = conv_model.fit(X,labels,epochs=100, batch_size=20, shuffle=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pyplot.figure()\n",
    "fig.suptitle('CNN LOSS', fontsize=14)\n",
    "# pyplot.plot(cnnScores.history['val_loss'],label=\"CNN Train\", color=\"red\")\n",
    "pyplot.plot(cnnScores.history['loss'],label=\"CNN Train\", color=\"green\")\n",
    "\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.ylabel('loss(CE)')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
